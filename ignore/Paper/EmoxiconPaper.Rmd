---
title             : "Russian Trolls & Emoxicon"
shorttitle        : "Emoxicon"

author: 
  - name          : "Tara L. Valladares"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    email         : "tls8vx@virginia.edu"
    address       : "Postal address"
  - name          : "Hudson Golino"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Virginia"

authornote: |
  This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. 1842490. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.

abstract: |
  This will be the abstract.
  
bibliography      : trolls.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, warn = FALSE
                      # ,cache=TRUE, autodep=TRUE, cache.comments=FALSE
                      )
knitr::knit_hooks$set(inline = function(x) # add commas to long numbers
  {   if(!is.numeric(x)){     x   }else{
    prettyNum(round(x,2), big.mark=",")    } }
  )

```

```{r load}
library(bookdown)
library(gridExtra)
library(papaja)
library(ggplot2)
library(emoxicon)
library(citr)
library(eRm) 

# source("EmoxiconPaperAnalysis.Rmd")
load("EmoxiconPaperAnalysis-May-21-2020-dat.RData")
```

<!-- To look for numbers that are NOT called by the r script (and thus need to be double double checked), search for 'BY HAND' -->

Introduction
============

<!-- Human communication relies heavily upon digital messages sent through -->
<!-- email, text messaging, and social media platforms. Developing methods -->
<!-- that can analyze unstructured text is therefore critical in numerous -->
<!-- fields, including psychology, political science, and economics. -->
<!-- Specifically, the need for methods of text analysis grows as the broad -->
<!-- spectrum influence of social media platforms such as Facebook and -->
<!-- Twitter increases. As social media platforms are frequent sites of both -->
<!-- information and disinformation campaigns, efforts to identify and -->
<!-- understand these processes are limited by the available tools. In this -->
<!-- paper, we will introduce a new method of emotion extraction and describe -->
<!-- an application to a dataset. -->

<!-- State Sponsored Disinformation and Russian Trolls -->
<!-- ------------------------------------------------- -->

The study of misinformation intersects innumerable fields.


In this following sections, we will make the argument that the quantification of emotion in text is critical in understanding how the IRA-linked Twitter accounts spread misinformation. Following, we will introduce Emoxicon - a new method of extracting emotion from text using psychometric modeling.



State sponsored disinformation campaigns are not a new phenomenon.
Purposeful efforts to spread false information and \"fake news\" have
been documented since ancient Egypt and Rome. With the rise of the
internet and social media, such campaigns can be conducted at a level
and size that was previously impossible. The Russian state commonly
employs disinformation campaigns in an effort to influence foreign
politics. These campaigns utilize a variety of strategies to sow
discord, including online media manipulation, cyber-espionage, and
falsely inciting protests in the real world
[@richey2018russia; @linvill2019ira].


<!-- Both trolls and bots have -->
<!-- been extensively used by Russia, and other governments, to manipulate -->
<!-- social media and political discourse around the world. -->

During the 2016 U.S. presidential election, Russian troll farms posed as
U.S. natives on Twitter and other social media cites in an attempt to influence political discourse
and opinion [@diresta2019tactics]. The term "trolls" or "sock puppet" accounts is commonly used to described social media accounts that claim to be some person from a certain background or position, while actually being under direct control of a hidden third party. This is similar but in contrast to "bots" which perform similar actions to trolls but are directed by a computer program rather than a real person. 
These actions eventually lead to the indictment of 13 Russian individuals and three Russian entities by the United States Justice Department on
charges relating to interference in the US presidential election
[@wapoRussian2018]. The Internet Research Agency (IRA), a company based
in St. Petersburg, Russia, was among the companies charged and has been a
primary focus of investigations into state-sponsored Russian
interference in U.S. politics [@schiff2018trolls]. The IRA, in particular, has been described as running "like a sophisticated marketing agency" with a budget of at least $25 million US dollars and one thousand employees in its efforts to spread misinformation online [@diresta2019tactics]. 

<!-- After the Justice -->
<!-- Department released the Twitter handles associated with the IRA, Clemson -->
<!-- university researchers Darren Linvill and Patrick Warren downloaded all -->
<!-- tweets associated with these accounts and made the dataset publicly -->
<!-- available for researchers [@linvill2019original]. The full dataset -->
<!-- consists of nearly 3 million tweets from 2,800 accounts. -->

Misinformation and troll accounts on social media are a new and evolving threat to democracy and fair and free elections worldwide [@sunstein2018republic; diresta2019tactics].
Extensive research has focused on how, why, and with whom the IRA-linked accounts interacted with on Twitter. Understanding the role that the Twitter accounts played is critical in identifying future fake Twitter accounts and limiting the impact of malicious actors in shaping public opinon. ((something about studying emotion, more citations here))

The actions of Russian trolls outside of the 2016 election suggest that their main purpose is sowing discord [@broniatowski2018vaccines].


### The Role of Twitter and Emotion in Politics

Twitter and other social media sites play a substainal role in shaping public opinion. Social media use has been shown to predict political participation, protest activity, and voting [@valenzuela2013protest; skoric2016social]. But as a whole, social media users tend to follow and interact with accounts with similar beliefs, forming "echo chambers" online [@del2016spreading; @tornberg2018echo; @garrett2009echo]. More active social media users tend to be more polarized and to follow fewer sources of information [@schmidt2017anatomy; @bessi2015trend]. Politically active twitter users rarely retweet content from accounts or news sources of different political parties; in @boutet2012retweet the majority of all interactions occurred between users with homologous polticial views. Though users largely retweet homologous opinions, user-to-user mentions ("@", or tagging another user in a tweet) frequently cross political lines [@boutet2012retweet; @conover2011retweet]. But exposure to different political views may not reliably prevent polarization, especially if users are interacting with oppositing, polarizing content from either real or troll accounts [@karlsen2017echo; @yardi2010dynamic]. In fact, several studies have found a "backfire" response where exposure to opposing views increases polarization [@bail2018exposure; @nyhan2010corrections].

Emotion plays a significant role in driving public opinion and online political discourse [@peng2017interplay; @gonzalez2012emotions; @mackuen2010civic]. Shifts in emotional arousal on a political discourse forum were linked to shifts in public opinion [@gonzalez2012emotions]. Influential Twitter users are more likely to tweet more negatively, and more emotional tweets are more likely to spread rapidly and be shared widely [@dang2013influentials; @brady2017emotion]. Supporting this, politicians with extreme ideological positions also have more Twitter followers [@hong2016politicalpolar]. The use of moral-emotional language increases message spread among political leaders to their followers [@brady2019ideological]. The use of anger and disgust may be especially impactful among conservative leaders [@brady2019ideological]. This may be driven by either reader characteristics or the topic. For example in @brady2017emotion, words reflecting anger increased sharing for climate change tweets, while positive emotions increased sharing for same-sex marriage. The impact of emotion on the spread of ideas is not limited to Twitter; one study using data from The New York Times found that articles that elicited stronger emotional arousal (i.e., awe, anger, and anxiety) were more likely to be shared [@berger2012nyt]. Using the Depechemood++ lexicon, @guerini2015emotions found that similar emotions (annoyed, angry, and inspired) also increased the likelihood that an article on the news website Rappler.com was spread. Further, moral-emotional language may have more of an impact in spreading ideas within-groups than between-groups, contributing to polarization and the "echo chamber" effect [@brady2017emotion]. Anger, specifically, may increase partisan beliefs and susceptibility to misinformation [@suhay2018role; @wollebaek2019anger; @mackuen2010civic]. 



It is clear that emotion plays a critical role in shaping political thought online. 
Importantly, current research on the activies of Russian IRA accounts suggests that they leveraged both the role of emotion and current echo chamber landscape to spread political misinformation. @zannettou2019disinformation showed that the Russian troll tweets are more negative and less positive than tweets from random subset of twitter users. In fact, some of the most popular IRA tweets were also the most racist and offensive [@freelon2020russian]In addition, Twitter users with more homologous social networks were more likely to interact with troll accounts [@bail2020trolls] and troll accounts were largely interacted with users already within their political cluster [@stewart2018retweet, @freelon2020russian]. The IRA troll accounts were also retweeted more by conservatives than liberals [@badawy2018analyzing]. 

We do not have a thourgouh understanding of the IRA accounts' use of emotion...


### Paragraph about methods of studying emotion in text

Because both typical human communication and disinformation campaigns
commonly occur on mediums characterized by brief segments of texts
(e.g., tweets), there is a great need for flexible, low-computation
methods of emotion detection that reliably work on relatively short
documents.

Aims
----

The purpose of the current study is to introduce a novel method of
emotion detection, termed Emoxicon, and detail its application to a
dataset of tweets sent by Russian Trolls. *Emoxicon* combines lexicon scoring with Rasch modeling to understand the distribution and probability of emotion categories.



### Russian Trolls Dataset

The IRA twitter data was made accessible by FiveThirtyEight and researcher's Linvill and Warren (2019).
The topical content of the Russian troll tweets ranges widely.
@linvill2019original consolidated the data and documented four major categories of English-language accounts that were active before the 2016 election: right trolls, left trolls, news feeds, and hashtag gamers. In the current analysis, we focused on only tweets from right-wing and left-wing troll accounts. 

The troll accounts were actively involved in the creation and dissemination of polticized content and propaganda [@zannettou2019disinformation].
Beyond following opposite political leanings, the content of the left-wing and right-wing troll tweets focused on separate topics. Political tweets from right-wing accounts largely supported Donald Trump as the presidential nominee and attacked Hilary Clinton. Other popular right-wing topics included anti-Islam sentiment and terrorism, liberal media bias, gun rights, and supporting the police  [@golino2020ega]. 

In contrast, while political tweets from left-wing accounts largely attacked Trump, they less frequently either attacked or supported Clinton [@linvill2019original]. They also largely tweeted from a pro "Black Lives Matter" perspective, focusing on topics such as police brutality, racism in America, current events involving the deaths of black Americans (e.g., Trayvon Martin, Ferguson and Michael Brown), and popular black musicians and media [@golino2020ega]. It is notable that a majority of the Russian left-wing troll accounts were specifically posing as black Americans instead of the many other diverse and divisive liberal perspectives, such as LGBTQ+, muslim, or feminist voices [@freelon2020black]. 

The majority of tweets from all accounts were deemed innocuous camouflage tweets; that is, the tweets were not political, but were instead contained
mundane interactions with followers or references to popular culture
[@linvill2019ira]. There were apparent differences in how the account categories tweeted, though. For example, the right-wing trolls had less camouflage tweets than the left-wing trolls; over half of tweets from left-wing troll accounts were camouflage tweets, compared to less than 15% of tweets from right-wing troll accounts [@linvill2019ira]. This suggests that left-wing and right-wing troll accounts were not only talking about different subjects but also employing different strategies in their attempts at political influence. 


Emoxicon
========

*Emoxicon* is a novel method of analyzing the emotional content of text. By combining lexicon-based scoring with Rasch modeling, emoxicon provides a low-computation analysis of the probability that different emotions categorioes appear within text. Lexicon-based analysis methods are commonly used to identify emotion within text [@gonzalez2012emotions; @peng2017interplay; @brady2017emotion]. Our contribution lies in the use of Rasch models to quantify the distribution and likelihood of the co-occurance of emotions and the "emotional voice" of the author. 


### Lexicon Scoring

We used the DepecheMood++ lexicon created by
[@araque2018depechemood]. Lexicons form the basis of most methods of emotion detection. Lexicons are dictionaries that contain features (such as words or punctuation), the category they belong to, and their designated score. DepecheMood++ is a high-coverage emotion lexicon that
contains roughly 37,000 terms and their associated probability
weights for 8 emotion categories. The lexicon was created by scraping
data from the news website Rappler which features a native "Mood
Meter" interface on each article. Readers of the site are encourage to
select one or more of eight reactions (Afraid, Amused, Angry, Annoyed, Don't
Care, Happy, Inspired, or Sad) to the article. DepecheMood++ has several
features that make it particularly useful. DepecheMood++ was
naively crowdsourced from at least one million responses to over 53,000 documents; it did not rely on hand-annotation by knowledgeable participants [@araque2018depechemood]. As a result, DepecheMood++ is much larger and covers more terms than other commonly used lexicons. Lexicon-based analyses are generally limited by the lexicon's size and complexity. The larger the lexicon, the more robust the scoring can be. Smaller lexicons may be poor matches to a target text if there is little overlap in words, and significant bias can occur when a target text is poorly matched to the lexicon.Previous work has shown that the Depechemood++ lexicon performs as well or better than other emotion lexicons in text analysis  [@araque2018depechemood; @staiano2014depechemood].

A simple bag-of-words method is applied to score the emotional content
of a given document. When using bag-of-words, all grammar and word placement
is discarded to create an orderless set of word counts. Though relatively crude, bag-of-words can produce compelling results on its own or in combination with machine learning techniques. Bag-of-words combined with standard machine learning algorithms can produce accuracy rates in tweet sentiment classification around 70-80%, which improves with the addition of sentiment lexicons [@dasilva2014tweet]. In the original Depechemood++ lexicon, each word is assigned a weight for each of the eight dimensions. Here, the lexicon is condensed;
each word in the lexicon becomes associated with the emotion category
with the highest probability weight. Then, each tweet is assigned a sum
score of how many words are most highly associated with each emotion
category. This aids in the scoring of the text and reduces noise in the Rasch model.

### Rasch Model Analysis

The Rasch model is used to evaluate the relative probability of an
emotion weight appearing in a given tweet [@Rasch1960]. By using the Rasch model, we
are able to analyze the fit of the emotion weights to the document. The
Rasch model originated in the field of psychometrics to relate scales
and questionnaires to the underlying latent trait. The
Rasch model is a logistic model that places persons and items on the
same scale to calculate the probability of a given person endorsing a
given item. Fundamentally, the Rasch model can be used to generate
latent trait scores for entities that produces a set of responses
determined by an underlying latent trait. The basic form of the Rasch
model for dichotomous items, as adapted from [@Rasch1960], is:

$$\textit{P}(\textit{X}_{ij} = 1 | \theta_i, \beta_j) = \dfrac{exp(\theta_i - \beta_j)}{ 1 + exp(\theta_i - \beta_j)}$$

Where $\theta$ represents the trait level of person $i$ and $beta$
represents the difficulty or location of item $j$. In Emoxicon, tweets
take the place of persons and emotional scores are represented as items.
Each tweet is scored based on how many words are present from each
emotion category. A mean split was performed on the emotion word counts
within each emotion category to dummy code each tweet as 1 (high) or 0
(low) for each category. For example, a tweet with a relatively high
amount of \"Happy\" words would receive a 1 for the \"Happy\" item. The
dichotomized scores are run through the Rasch model to produce trait
scores for the tweets and 'item' locations for the emotion categories.

An underlying assumption of the Rasch model is unidimensionality, which is the requirement that there is only one underlying latent trait driving all responses. In standard applications of the Rasch model, this is a trait such as math ability. Here, we propose that the dimension that the text is scored on is *emotional voice* of the author. 

Under the Rasch model, items receive estimates of their relative frequency of occurence on the latent dimension, also known as item difficulty or location. These estimates have meaningful order. An item with a lower estimate is more likely to be endorsed than an item with a higher estimate. If an item with a high estimate is endorsed, it is also likely that the lower estimate items will also be endorsed. Deviation from these assumptions will produce poor model fit. The item estimates are thus also estimates of conditional probability. That is, if an emotion label recieves a high estimate, this implies that the emotion label is both rare and generally appears alongside the lower difficulty items. If more rarely endorsed items do no co-occur with more commonly endorsed items, item and model fit will be poor. This conditional fit underlies the intepretation of the latent dimension as the emotional voice of the author. 



Methods
=======

Data Pre-processing
-------------------

The purpose of this analysis is to examine differences in tweets written by the IRA among the left-wing and the right-wing troll accounts. We will refer to such tweets as *authored* content. By removing non-authored tweets, we ensure that all the tweets support the goals of the accounts and do not belong to accounts with other "voices." To this end, we included only English-language troll accounts labeled as Left-wing (\"Left\") or Right-wing (\"Right\") by @linvill2019original. URLs, Retweets, manual reposts (i.e., tweets that begin with \"rt\"), and duplicate tweets were removed. 

Because the Depechmood++ lexicon was sourced from news articles, it contains emotion associations for a number of politically relevant words, such as \"Hillary,\" \"Clinton,\" and \"Trump\". We removed a small set of topically relevant terms that we anticipated had different affective associations between the left-wing and right-wing accounts (see the Appendix for a full list of removed words). That is, left-wing and right-wing trolls may use the word \"Trump\" just as frequently, but that word does not have the same relationship to the tweets true emotional content for each group. As these words were used often, they also would artificially inflate their respective category frequency. Similarly, multiword hashtags (e.g., "#blacklivesmatter") were not split up and scored to prevent misleading category inflation as the emotional valence of the whole hashtag was likely not a sum of its parts. 

Analysis Plan
-------------

We ran two separate but complimentary applications of the *Emoxicon* method to the Russian Trolls dataset: an omnibus Rasch model for the `r sum(table(unique(trolls[c("author", "account_type")])$account_type))` number of Twitter accounts, and `r length(catright)` Rasch models for each individual account. The omnibous Rasch model included all cleaned tweets from both left-wing and right-wing trolls. In this strategy, we are able to identify differences between left-wing and right-wing trolls in the majority of the authored tweets. However, these broad group-level differences obscur the actions of less productive accounts and are largely dominated by a handful of mega-accounts with thousands of self-authored tweets. To compliment the omnibous model, we also ran individual Rasch models for Twitter accounts. This stratgey allows us to examine differences between accounts regardless of their productivity. For the individual models, only accounts with at least 30 tweets were included to sufficiently fit each Rasch model [@linacre1994samplesize]. Each method used the same data scored with the Depechemood++ lexicon [@araque2018depechemood]. All models and fit statistics were produced using the R package eRm [@eRm2020]. Exact estimation of full zero/complete response patterns are not available with the eRm conditional maximum likelihood estimator. This is an acceptable trade off in exchange for unbiased person and item estimates [@mair2007cml] and because person estimates are not of direct interest in the Emoxicon method.

The main variable of interest was the estimated item parameters produced by the Rasch model, specfically the item difficulties. In the overarching model, we used Andersen's likelihood ratio test in the eRm pacakge to identify differences in item difficulties between left-wing and right-wing trolls. 

Because the mean of either the person or item parameters of the Rasch model must be set to zero before estimation to establish the scale and the individual models use separate data, item parameters are not directly comparable across individual Rasch models. Therefore to compare the relative difficulties between models, item parameters from the individual models were transformed into ranks from 1 (easiest) to 8 (hardest) within each model. Ties in rank were broken randomly. The distribution of the ranks could then be examined for consistency within and differences between Right and Left trolls. If an individual account did not use any words from a specific emotion category, that emotion category was given the rank of 8 (hardest to endorse). 

To evalute the ranks of the emotion categories in the individual models, we examined their distribution using Kolmogorov-Smirnov distribution and Welch t-tests [@corder2014nonparametric]. In addition, we evaluated the consistency of the item difficulties within the left-wing and right-wing troll groups using multiinformation (total correlation) from the R package infotheo [@meyer2008infotheo], and the diversity of the emotion labels using the gini coefficient [@ong2018emodiversity].

Our final sample consisted of `r nrow(trolls)` tweets from `r table(unique(trolls[c("author", "account_type")])$account_type)[["Right"]]` right-wing accounts ($n_{tweets}$ = `r sum(trolls$account_type == "Right")`) and `r table(unique(trolls[c("author", "account_type")])$account_type)[["Left"]]` left-wing accounts ($n_{tweets}$ = `r sum(trolls$account_type == "Left")`). Among twitter handles with at least 30 tweets, there were `r sum(catright)` right-wing accounts ($n_{tweets}$ = `r tweets30right`) and `r sum(catleft)` left-wing accounts ($n_{tweets}$ = `r tweets30left`). Tweets dated from `r stringi::stri_split_regex(min(trolls$publish_date), " ")[[1]][1]` to `r stringi::stri_split_regex(max(trolls$publish_date), " ")[[1]][1]`. See Table\ \@ref(tab:tweetTab) for more information on tweet distribution of the final sample.


```{r tweetTab}

# rows - left wing and right wing
tweetTab<- data.frame(
  "x" = c("Left-wing, all accounts","Left-wing, 30+ tweets", "Right-wing, all accounts","Right-wing, 30+ tweets"),
  "Accounts, n" = c(table(unique(trolls[c("author", "account_type")])$account_type)[["Left"]],
                    sum(catleft),
                    table(unique(trolls[c("author", "account_type")])$account_type)[["Right"]],
                    sum(catright)),
  "Total Tweets" = c(sum(trolls$account_type == "Left"),
                tweets30left,
                sum(trolls$account_type == "Right"),
                tweets30right),
  "Minimum" = c(min(table(trolls[which(trolls$account_type=="Left"),"author"])),
                30,
                min(table(trolls[which(trolls$account_type=="Right"),"author"])),
                30),
  
  "2nd Quartile" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[2],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[2],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[2],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[2]),
  
  "Median" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[3],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[3],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[3],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[3]),
  
  "3rd Quartile" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[4],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[4],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[4],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[4]),
  
  "Maximum" = c(max(table(trolls[which(trolls$account_type=="Left"),"author"])),
                max(table(trolls[which(trolls$account_type=="Left"),"author"])),
                max(table(trolls[which(trolls$account_type=="Right"),"author"])),
                 max(table(trolls[which(trolls$account_type=="Right"),"author"])))
)
colnames(tweetTab) <- c("x", "Accounts, n", "Total Tweets", "Minimum", "2nd Quartile", "Median", 
                        "3rd Quartile", "Maximum")

apa_table(
  tweetTab
  , caption = "Distribution of Tweets in Accounts"
  , note = "Tweets removed during pre-processing are not included."
  , escape = TRUE
)


```

Results
=======

Overarching Rasch Model
-------------------
<!-- BY HAND -->
### Model Fit
Overall model fit for the full Rasch model was appropriate. Only `r pmis$PersonMisfit`% of tweets showed significant misfit using a Chi-square based Z-value cutoff of 1.96. The items *Amused* and *Inspired* showed misfit based on chi-squared item fit statistics (
$\chi$(`r ifit$i.df["AMUSED"]`) = `r ifit$i.fit["AMUSED"]`, p = .001 and 
$\chi$(`r ifit$i.df["INSPIRED"]`) = `r ifit$i.fit["INSPIRED"]`, p < .001
, respectively). Due to the large sample size, and the results in the following sections, the misfit in these items is not of great concern.
To check for multidimensionality, we performed a principal components analysis on the Rasch model residuals. The largest eigenvalue was `r round(rasch_pca$pca$eigen.values[1],2)`, indicating that there was not a significant impact of multidimensionality on the model fit [@linacre1998rfa].

```{r}
scores<-data.frame(scores = rowSums(trolls_models$full_model$X), 
                   account_type = trolls$account_type)
tweetsscores<-t.test(scores~account_type, scores)

```

Items were generally well-matched to tweet scores (Figure\ \@ref(fig:PImap)). 
Right-wing tweets had slightly higher raw scores (M = `r mean(subset(scores, account_type == "Right")[["scores"]])`, SD = `r sd(subset(scores, account_type == "Right")[["scores"]])`) than Left-wing tweets M = `r mean(subset(scores, account_type == "Left")[["scores"]])`, SD = `r sd(subset(scores, account_type == "Left")[["scores"]])`;
 *t*(`r tweetsscores$parameter`) = `r tweetsscores$statistic`, *p* < .001
), though the difference was empirically small. In the Rasch model, *Don't Care* was the easiest item with the lowest difficulty, while *Happy* was the item with the highest difficulty. The difficulties of other items were estimated to be relatively close to one another, indicating that the categories were used at relatively similar rates when both Left-wing and Right-wing trolls were combined.

(ref:fig-PImap) There were `r (1-sum(table(pparameters$thetapar))/nrow(trolls))*100`%  tweets with full zero/complete response patterns. They are not included in the pictured person distribution.

```{r PImap, fig.cap = "(ref:fig-PImap)"}
plotPImap(trolls_models$full_model, sorted = TRUE,
         cex = .5)
```

### Left-wing and Right-wing Differences
<!-- BY HAND -->
The Andersen's likelihood ratio test showed significant differences between the Left-wing and Right-wing troll tweets ($\chi$(7) = `r lrres$LR`, p < .001; Figure\ \@ref(fig:llres)) [@eRm2020]. The items *Amused*, *Afraid*, and *Annoyed* were more difficult among Left-wing Tweets. *Inspired* was more difficult for Right-wing tweets. *Don't Care* and *Angry* were also more difficult for Right-wing tweets, but to a much smaller degree.The items *Happy* and *Sad* were similarly used between both Left-wing and Right-wing trolls. 


(ref:fig-llres) Items closer to the black identity line were estimated more similarly between Left-wing and Right-wing tweets. The 95% confidence intervals are shown in blue for the identity line and in red for the item difficulties.

```{r llres, fig.cap = "(ref:fig-llres)"}
plotGOF(lrres, tlab = "item",
        conf = list(ia = FALSE, col = "red", lty = "dotted"),
        smooline = list(gamma = .95, col = "blue", lty = "solid"),
        main = "Likelihood Ratio Differences between Troll Groups", 
        xlab = "Item Difficulties for Left-wing Tweets",
        ylab = "Item Difficulties for Right-wing Tweets",
        cex = .7, cex.main = .2, cex.axis = .2, cex.lab =.2
          )

```


Individual Rasch Models
-----------------------

### Model Fit
We fit `r length(trolls_models$group_models)` Rasch models for each of the individual twitter handles with at least 30 authored tweets. Among these models, there were `r table(err_models)[["HAPPY"]]` models with full zero responses for the category *Happy* and `r table(err_models)[["AFRAID"]]` model with full zero responses for the category *Afraid*. The average percentage of misfitting persons was 
`r mean(manymods_pmis_total[modsL])`% (SD = `r sd(manymods_pmis_total[modsL])`) for Left-wing accounts and 
`r mean(manymods_pmis_total[!modsL])`% (SD = `r sd(manymods_pmis_total[!modsL])`) for Right-wing accounts. Item misfit was also generally low (Table\ \@ref(tab:ifittab)). The majority of items misfit in less than 6% of models, except for *Amused*, *Happy*, and *Inspired*. Overall, the measures of model fit were appropriate.


```{r ifittab}
ifittab<-manymod_ifit_tab
apa_table(ifittab,
          caption = "Percent of Models with Misfitting Items"
  # , note = "This table was created with apa_table()."
  , escape = TRUE)

```


### Category Ordering
<!-- BY HAND -->
Figure\ \@ref(fig:catplots) displays the distributions of the order of item difficulties for both left-wing and right-wing troll accounts. Mean differences were evaluted by using *t*-tests. Distributional differences were evaluted with Kolmogorov-Smirnov Tests [@corder2014nonparametric].
Across both groups, the hardest category was *Happy* for `r table(trolls_models$category_order$HAPPY)[["8"]]/length(trolls_models$group_models)*100`% of accounts. 
There were significant mean and distributional differences between left-wing and right-wing trolls for the categories 
*Angry* (*t*(`r ttests$ANGRY$parameter`) = `r ttests$ANGRY$statistic`, *p* < .001; D = `r kstests$ANGRY$statistic`, *p* = < .001), 
*Annoyed* (*t*(`r ttests$ANNOYED$parameter`) = `r ttests$ANNOYED$statistic`, *p* < .001; D = `r kstests$ANNOYED$statistic`, *p* < .001), 
*Sad* (*t*(`r ttests$SAD$parameter`) = `r ttests$SAD$statistic`, *p* < .001; D = `r kstests$SAD$statistic`, *p* < .001), 
and *Afraid* (*t*(`r ttests$AFRAID$parameter`) = `r ttests$AFRAID$statistic`, *p* < .001; D = `r kstests$AFRAID$statistic`, *p* < .001; see Table\ \@ref(tab:msdcat) for means and standard deviations). The category *Don't Care* showed distributional differences (D = `r kstests$DONT_CARE$statistic`, *p* = 0.049), but not mean differences. There were no differences in the item difficulty orders for the categorys *Amused*, *Inspired*, or *Happy*.


```{r msdcat}

msdcat <- data.frame("Category" = c("Amused","Angry","Annoyed",
                                    "Don't Care","Inspired",
                                    "Sad", "Afraid", "Happy"),
                     "Mean (SD) - Right-Wing" = paste0(
                       format(round(colMeans(
                         trolls_models$category_order[catright,]),2), nsmall=2),
                       " (",
                       format(round(apply(
                         trolls_models$category_order[catright,],2,sd),2), nsmall=2),
                       ")"),
                     "Mean (SD) - Left-Wing" = paste0(
                       format(round(colMeans(
                         trolls_models$category_order[catleft,]),2), nsmall=2),
                       " (",
                       format(round(apply(
                         trolls_models$category_order[catleft,],2,sd),2), nsmall=2),
                       ")"), stringsAsFactors = F
)
colnames(msdcat) <- c("Category", "Mean (SD) - Right-Wing",  "Mean (SD) - Left-Wing")


apa_table(
  msdcat
  , caption = "Means and Standard Deviations of Emotion Category Orders"
  # , note = "This table was created with apa_table()."
  , escape = TRUE
)
```


(ref:fig-catplots) The distributions of emotion categories within accounts when ordered from 1 (easiest) to 8 (hardest). \u002A indicates significant differences between left-wing and right-wing accounts based on *t* tests. \u2020 indicates significant differences based on Kolmogorov-Smirnov distribution tests.


```{r catplots, fig.cap = "(ref:fig-catplots)", fig.height=5.5}

grid.arrange(catplotsR + theme(text = element_text(size=rel(8)),
                               strip.text.x = element_text(size = 5.5),
                               axis.title.x = element_blank()), 
             
             catplotsL + theme(text = element_text(size=rel(8)),
                               strip.text.x = element_text(size = 5.5)),
             ncol=1)

```


### Gini Index (Emodiversity)
Following @ong2018emodiversity's emodiversity method, we used the Gini coefficient to estimate the diversity in category usage between left-wing and right-wing trolls. High gini coefficient values indicate more diversity (more inequality) among emotion categories. 
We used the raw emotion scores rather than the Rasch model dichotomized scores.
Left-wing trolls showed more inequality among emotion categories than right-wing trolls when the gini coefficient was calculated either across all tweets 
(left-wing = `r ginitweetresults$estimate["mean in group Left"]`, right-wing = `r ginitweetresults$estimate["mean in group Right"]`; 
(*t*(`r ginitweetresults$parameter`) = `r ginitweetresults$statistic`, *p* < .001) 
or within authors
(left-wing = `r giniauthorresults$estimate["mean in group Left"]`, right-wing = `r giniauthorresults$estimate["mean in group Right"]`; 
(*t*(`r giniauthorresults$parameter`) = `r giniauthorresults$statistic`, *p* < .001). 


### Multiinformation

We calculated multiinformation (also known as total correlation  [@meyer2008infotheo]) with bootstrapped confidence intervals for the category orders for the left-wing and right-wing accounts to understand the consistency in the orders within groups. 
Higher values of multiinformation signify higher entropy, that is, lower relationships between variables. 
For left-wing accounts, multiinformation was 
`r boot.left$t0` (95% CI [`r bci.left$normal[2]`, `r bci.left$normal[3]`], bias =  `r mean(boot.left[["t"]]) - boot.left$t0`); 
for right-wing accounts, multiinformation was `r boot.right$t0` (95% CI [`r bci.right$normal[2]`, `r bci.right$normal[3]`], bias =  `r mean(boot.right[["t"]]) - boot.right$t0`). 
We also bootstrapped the average multiinformation among a random ordering of the numbers 1 through 8, resulting in a maximum value of multiinformation value of `r boot.random$t0` (95% CI [`r bci.random$normal[2]`,`r bci.random$normal[3]`]) for a data structure like the category orders in this study. Both left-wing and right-wing trolls showed more cohesion in their category orders than would be expected by chance, but they did not differ from one another.

Discussion
==========




*Happy* was the hardest emotion category for both left-wing or right-wing trolls when examining the total number of tweets and the individual models.

Of note, the emotion categories with that showed misfit most often (*Amused*, *Happy*, and *Inspired*) were also the categories that generally did not show differences between Left-wing and Right-wing trolls.

Interpretation
--------------

The differences in emotion expression may be linked to different methods of eliciting emotion. Different purposes, topics eliciting different emotions

It is critical to interpret the results of this study in context of its methods. Emotion is not a universal, context-free phenomenon; statements that are neutral in one context may elicit powerful reactions in another. The emotion categories delinated in the Depechemood++ lexicon were sourced from a specific time and group membership. When a tweet is rated highly on *Happy*, it does not imply that all readers of the tweet would have the same reaction. This may be even more true when dealing with highly politically and emotionally charged content that was written to elicit strong emotion reactions.

We propose that differences in emotion expression in this study should rightly be interpreted as differences in how one, perhaps neutral, subset of readers may react. We do not believe that these differences are not true or present in reality - rather that it is an overstep to assume that every person who reads a left-wing troll tweet is more likely to react with anger than if they read a right-wing troll tweet.


Future Directions
-----------------

Limitations
-----------

Conclusions
-----------


Words removed from Lexicon
==========================

`r paste(exclude, " ")`
