---
title             : "Russian Trolls & Emoxicon"
shorttitle        : "Emoxicon" 

author: 
  - name          : "Tara L. Valladares"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    email         : "tls8vx@virginia.edu"
    address       : "Postal address"
  - name          : "Hudson Golino"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Virginia"

authornote: |
  This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. 1842490. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.

abstract: |
  This will be the abstract.
  
bibliography      : trolls.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, warn = FALSE
                      # ,cache=TRUE, autodep=TRUE, cache.comments=FALSE
                      )
knitr::knit_hooks$set(inline = function(x) # add commas to long numbers
  {   if(!is.numeric(x)){     x   }else{
    prettyNum(round(x,2), big.mark=",")    } }
  )

```

```{r load}
library(bookdown)
library(gridExtra)
library(papaja)
library(ggplot2)
library(emoxicon)
library(citr)
library(eRm) 

# source("EmoxiconPaperAnalysis.Rmd")
load("EmoxiconPaperAnalysis-July-1-2020-dat.RData") # for faster running for the draft
```

<!-- To look for numbers that are NOT called by the r script (and thus need to be double double checked), search for 'BY HAND' -->

Introduction
============

<!-- Human communication relies heavily upon digital messages sent through -->
<!-- email, text messaging, and social media platforms. Developing methods -->
<!-- that can analyze unstructured text is therefore critical in numerous -->
<!-- fields, including psychology, political science, and economics. -->
<!-- Specifically, the need for methods of text analysis grows as the broad -->
<!-- spectrum influence of social media platforms such as Facebook and -->
<!-- Twitter increases. As social media platforms are frequent sites of both -->
<!-- information and disinformation campaigns, efforts to identify and -->
<!-- understand these processes are limited by the available tools. In this -->
<!-- paper, we will introduce a new method of emotion extraction and describe -->
<!-- an application to a dataset. -->

<!-- State Sponsored Disinformation and Russian Trolls -->
<!-- ------------------------------------------------- -->

The study of disinformation intersects a myriad of different fields, including psychology, sociology, politics, computer science, and engineering. These fields often converge on the topic of state sponsored disinformation campaigns and their detection, influences, and impacts. Though organized efforts to spread disinformation are not new, the rise of the internet and social media as major players in shaping public opinion have allowed such campaigns to be conducted at a scale that was previously impossible. Thus, modern text analysis techniques are necessary to understand and quantify these largely text-based disinformation campaigns. As emotion plays a critical role in human communication, so is the quantification of emotion in text critical in understanding how Russian-linked Twitter accounts spread disinformation. In the current paper, we will first briefly summarize what is known about the Russian troll accounts, the role of Twitter (https://twitter.com) in politics, and the role of emotion in spreading (dis-)information. Following, we will introduce Emoxicon - a new method of extracting emotion from text using psychometric modeling, and its application to Russian-linked Twitter accounts around the time of the US 2016 presidential election. 




<!-- State sponsored disinformation campaigns are not a new phenomenon. -->
<!-- Purposeful efforts to spread false information and \"fake news\" have -->
<!-- been documented since ancient Egypt and Rome.  -->
<!-- With the rise of the -->
<!-- internet and social media, such campaigns can be conducted at a level -->
<!-- and size that was previously impossible.  -->

<!-- Both trolls and bots have -->
<!-- been extensively used by Russia, and other governments, to manipulate -->
<!-- social media and political discourse around the world. -->

### Russian-linked Troll Accounts

The Russian state has historically engaged in disinformation campaigns in an effort to influence foreign
politics [@broniatowski2018vaccines; @mejias2017disinformation]. These campaigns have utilized a variety of strategies to sow discord, including online media manipulation, cyber-espionage, and even falsely inciting protests in the real world [@richey2018russia; @linvill2019ira].
During the 2016 U.S. presidential election, Russian-based Twitter accounts posed as U.S. natives on Twitter and other social media sites to influence political discourse and public opinion [@diresta2019tactics]. Such accounts are often called "troll" or "sock puppet" accounts; they are social media accounts that claim to be a a certain identity when the account is actually under the direct control of an obscured third party. 
<!-- In contrast "bots" are automated accounts directed by a computer program.  -->
These actions eventually culminated in the indictment of thirteen Russian individuals and three Russian entities by the United States Justice Department on charges relating to interference in the US presidential election
[@wapoRussian2018]. The Internet Research Agency (IRA), a company based in St. Petersburg, Russia, was among the companies charged and has been a primary focus of investigations into state-sponsored Russian
interference in U.S. politics [@schiff2018trolls]. The IRA, in particular, has been described as "a sophisticated marketing agency" using a budget of at least $25 million US dollars and one thousand employees to spread disinformation online in the United States [@diresta2019tactics]. 

The IRA Twitter data was made accessible by FiveThirtyEight and the researchers Linvill and Warren [@fivethirtyeight2018trolls; @linvill2019original].
The topics tweeted about by the Russian troll accounts varies widely.
@linvill2019original consolidated the data and documented four major categories of English-language accounts that were active before the 2016 election: right-wing trolls, left-wing trolls, news feed accounts, and hashtag gamers. In the current analysis, we focused on only tweets from right-wing and left-wing troll accounts. 

The right-wing and left-wing troll accounts were actively involved in the creation and dissemination of politicized content and propaganda [@zannettou2019disinformation]. Political tweets from right-wing accounts generally followed popular conservative talking points of the time, supporting Donald Trump as the Republican presidential nominee and attacking Hillary Clinton, the Democratic party presidential candidate. Other popular right-wing topics included anti-Islam sentiment and terrorism, liberal media bias, gun rights, and supporting the police  [@golino2020ega]. Political tweets from left-wing accounts largely attacked Trump, but they less frequently either attacked or supported Clinton [@linvill2019original]. A small number of accounts supported Bernie Sanders, an independent candidate. The left-wing accounts largely tweeted from a pro "Black Lives Matter" perspective, focusing on topics such as police brutality, racism in America, current events involving the deaths of black Americans (e.g., Trayvon Martin, Ferguson, Missouri, and Michael Brown), and popular black musicians and media [@golino2020ega]. Approximately half of the left-wing troll tweets were from accounts that specifically posed as Black Americans [@freelon2020black]. Thus, the right-wing and left-wing trolls tweeted from opposite ends of the political spectrum and with few overlapping topics. 

<!-- It is notable that a majority of the Russian left-wing troll accounts were specifically posing as black Americans instead of the many other diverse and divisive liberal perspectives, such as LGBTQ+, muslim, or feminist voices [@freelon2020black].  -->

Notably, the majority of tweets from both the left- and right-wing  accounts were deemed innocuous camouflage tweets by @linvill2019ira. These camouflage tweets were not overtly political but instead consisted of mundane interactions with followers or references to popular culture. There were apparent differences in how the account categories tweeted, though. For example, the right-wing trolls had less camouflage tweets than the left-wing trolls; over half of tweets from left-wing troll accounts were camouflage tweets, compared to less than 15% of tweets from right-wing troll accounts [@linvill2019ira]. This suggests that left-wing and right-wing troll accounts were not only tweeting about different subjects but also employing different strategies in their attempts at political influence. 

It is widely understood that social media disinformation campaigns pose a significant threat to representative democracies worldwide [@sunstein2018republic; @diresta2019tactics], though the final impact of the IRA's actions on the US 2016 election has been debated (for dissenting opinions see @boyd2018characterizingIRA and @zannettou2019disinformation). Nonetheless, extensive research has focused on how, why, where, and with whom the IRA-linked accounts spread disinformation, which will be explored further in the next section.
<!-- [e.g., @bail2020trolls; @stewart2018retweet; @zannettou2019disinformation].  -->
Understanding the roles that both Twitter and troll accounts play is critical in identifying and understanding disinformation campaigns and limiting the impact of malicious actors in shaping public opinion. 


### The Role of Social Media and Emotion in Politics

Social media has cemented itself as a major player in the American political process in less than two decades. In 2019, 69% of US adults used Facebook, with about 75% of users checking it at least once a day [@pew2019internet]. Political participation, protest activity, and voting have each been associated with social media behavior [@valenzuela2013protest; @skoric2016social; @min2018news; @halpern2017participation; @valenzuela2019paradox]. In conjunction, by 2018 every single US Congressional Representative and Senator had a Twitter account and only a handful lacked Facebook and YouTube accounts [@straus2018congress]. Because of social media's role in politics and opinion formation, there is an extensive body of research describing how the websites are used and how users interact with each other.

Though Twitter can be a highly valuable source of information for its users, its unmoderated content is not read and spread in unbiased manner. The results from @valenzuela2019paradox suggest that highly active social media users also tend to share more misinformation regardless of how (mis)informed these users actually are. As a whole, social media users tend to follow and interact with accounts that hold similar political beliefs, forming "echo chambers" online [@del2016spreading; @tornberg2018echo; @garrett2009echo]. Highly active social media users tend to be more polarized and to follow fewer sources of information [@schmidt2017anatomy; @bessi2015trend]. Politically active Twitter users rarely retweet content from accounts or news sources from different political parties. In @boutet2012retweet the majority of all interactions on Twitter occurred between users with homologous political views. While users largely retweet homologous opinions, user-to-user mentions (i.e., tagging another user in a tweet) frequently cross political lines [@boutet2012retweet; @conover2011retweet]. This cross-over exposure may not reliably prevent polarization though, especially if users are interacting with opposing, polarizing content from either real or troll accounts [@karlsen2017echo; @yardi2010dynamic]. In fact, a handful of studies have found a "backfire" response where exposure to opposing views increases polarization [@bail2018exposure; @nyhan2010corrections]. 

Emotion plays a significant role in driving public opinion and online political discourse [@peng2017interplay; @gonzalez2012emotions; @mackuen2010civic]. @gonzalez2012emotions found that shifts in emotional arousal on a political discourse forum were linked to corresponding shifts in public opinion. On Twitter, influential political users are twice as likely to tweet negatively about politicans and political parties, and more emotional political tweets tend to spread further and faster [@dang2013influentials; @brady2017emotion]. In @brady2017emotion, adding a single moral-emotional word (e.g., "hate" or "blame") to a tweet increased the expected sharing rate by 17%-24%, depending on the topic. The use of moral-emotional language is also associated with message spread from the political leaders to their followers [@brady2019ideological]. Similarly, politicians with extreme ideological positions also tend to have more Twitter followers [@hong2016politicalpolar]. 

Specific emotion categories have been identified as contributing to information spread. For example, the use of anger and disgust may be especially impactful among conservative political figures on Twitter [@brady2019ideological]. This may be driven by either reader characteristics or the topic. For example in @brady2017emotion, anger and sadness words increased sharing for climate change tweets, while positive emotions increased sharing for same-sex marriage.  The impact of emotion on the spread of ideas is not limited to Twitter and may be a more general phenomenon. One study using data from The New York Times found that articles which elicited stronger emotional arousal (i.e., awe, anger, and anxiety) were more likely to be shared; the odds that an article made the top shared list increased by 34% for every one standard deviation increase in anger, 30% for awe, and 21% for anxiety [@berger2012nyt]. @guerini2015emotions found that similar emotions (inspired, angry, and annoyed) most strongly influenced the likelihood that an article on the news website Rappler.com was shared or commented on. Further, moral-emotional language may have more of an impact in spreading ideas within-groups than between-groups, contributing to polarization and the "echo chamber" effect [@brady2017emotion]. Anger, specifically, may also increase partisan beliefs and susceptibility to misinformation [@suhay2018role; @wollebaek2019anger; @mackuen2010civic]. In total, the available evidence supports the role of emotion in spreading political ideas and information, though the impact of specific emotions may be context dependent.


<!-- It is clear that emotion plays a critical role in shaping political thought online.  -->
Current research on the activities of Russian IRA accounts suggests that they leveraged both the role of emotion and current echo chamber landscape to spread political disinformation. @zannettou2019disinformation showed that Russian troll tweets are more negative and less positive than tweets from random subset of one thousand Twitter users with similar posting activity. In fact, some of the most popular IRA tweets were also the most racist and offensive [@freelon2020russian]. 

Twitter estimates that by early 2018, approximately 1.4 million users (2% of active users) had interacted with IRA accounts [@twitter2018update]. @bail2020trolls surveyed 1,200 active Twitter users who identified as either a Republican or a Democrat and found that 9% had interacted with IRA accounts and 11.3% directly engaged with them. These higher percentages suggest that partisans were more likely to interact with IRA accounts. In the same study, stronger political interest and more homologous social networks were also associated with higher likelihood of IRA interactions. Other research also suggests that troll accounts largely interacted with users already within their political cluster [@stewart2018retweet; @freelon2020russian]. In addition, conservatives may be more likely to retweet IRA content than liberals [@badawy2018analyzing; @bail2020trolls], though it is unclear if this is due to either the IRA's actions or user characteristics. 

Aims
----
<!-- ((Here, summarize, briefly, the aims of the study. We want to use Emoxicon to quantify the emotions present in troll tweets.)) -->
Though emotion plays a critical role in shaping political thought online, we do not have a thorough understanding of how the IRA accounts' used emotion in their disinformation campaign. 
The purpose of the current study is to introduce a novel method of emotion detection termed Emoxicon, and detail its application to the IRA Twitter accounts. Emoxicon combines lexicon scoring with Rasch modeling to understand the distribution and probability of emotion categories.
Because so much of human communication now occurs on mediums characterized by brief segments of texts, there is a great need for flexible, low-computation methods of emotion detection that reliably work on relatively short documents.
Using Emoxicon, we aim to map out the distribution of emotions and this differs between both Right-wing and Left-wing trolls and the accounts within these groups.


Methods
=======

Emoxicon
--------

Emoxicon is a novel method of analyzing the emotional content of text. By combining lexicon-based scoring with Rasch modeling, Emoticon provides a low-computation analysis of the probability that different emotions categories appear within text. Lexicon-based analyses are already well-established methods used to identify emotion within text [@gonzalez2012emotions; @peng2017interplay; @brady2017emotion]. Our contribution lies in the use of Rasch models to quantify the distribution and likelihood of the co-occurrence of emotions and the "emotional voice" of the author. Emoxicon is a two part method that starts by scoring data using an emotion lexicon and then models the distribution of the emotion categories using the Rasch model.

### Lexicon Scoring

We used the DepecheMood++ lexicon created by
@araque2018depechemood. Lexicons form the basis of most methods of emotion detection. Lexicons are dictionaries that contain features (such as words or punctuation), the category they belong to, and their designated score. DepecheMood++ is a high-coverage emotion lexicon that contains roughly 37,000 terms and their associated probability weights for 8 emotion categories. The lexicon was created by scraping data from the news website Rappler which features a native "Mood Meter" interface on each article. Readers of the site are encourage to select one or more of eight reactions (Afraid, Amused, Angry, Annoyed, Don't Care, Happy, Inspired, or Sad) to the article. DepecheMood++ has several features that make it particularly useful. DepecheMood++ was naively crowdsourced from at least one million responses to over 53,000 documents; it did not rely on hand-annotation by knowledgeable participants [@araque2018depechemood]. As a result, DepecheMood++ is much larger and covers more terms than other commonly used lexicons. Lexicon-based analyses are generally limited by the lexicon's size and complexity. The larger the lexicon, the more robust the scoring can be. Smaller lexicons may be poor matches to a target text if there is little overlap in words, and significant bias can occur when a target text is poorly matched to the lexicon.Previous work has shown that the DepecheMood++ lexicon performs as well or better than other emotion lexicons in text analysis  [@araque2018depechemood; @staiano2014depechemood].

A simple bag-of-words method is applied to score the emotional content of a given document. When using bag-of-words, all grammar and word placement is discarded to create an orderless set of word counts. Though relatively crude, bag-of-words can produce compelling results on its own or in combination with machine learning techniques. Bag-of-words combined with standard machine learning algorithms can produce accuracy rates in tweet sentiment classification around 70-80%, which improves with the addition of sentiment lexicons [@dasilva2014tweet]. In the original DepecheMood++ lexicon, each word is assigned a weight for each of the eight dimensions. Here, the lexicon is condensed; each word in the lexicon becomes associated with the emotion category with the highest probability weight. Then, each tweet is assigned a sum score of how many words are most highly associated with each emotion category. This aids in the scoring of the text and reduces noise in the Rasch model.

### Rasch Model Analysis

The Rasch model [@Rasch1960] is used to evaluate the relative probability of an emotion weight appearing in a given tweet within the Emoxicon methodology. By using the Rasch model, we are able to analyze the fit of the emotion weights to the document. The Rasch model originated in the field of psychometrics to relate scales and questionnaires to the underlying latent trait. The Rasch model is a logistic model that places persons and items on the same interval-level scale to calculate the probability of a given person endorsing a given item. Fundamentally, the Rasch model can be used to generate latent trait scores for entities that produces a set of responses determined by an underlying latent trait. The basic form of the Rasch model for dichotomous items, as adapted from @Rasch1960, is:

$$\textit{P}(\textit{X}_{ij} = 1 | \theta_i, \beta_j) = \dfrac{exp(\theta_i - \beta_j)}{ 1 + exp(\theta_i - \beta_j)}$$

Where $\theta$ represents the trait level of person $i$ and $beta$
represents the difficulty or location of item $j$. In Emoxicon, tweets take the place of persons and emotional scores are represented as items. Each tweet is scored based on how many words are present from each emotion category. A mean split was performed on the emotion word counts within each emotion category to dummy code each tweet as 1 (high) or 0 (low) for each category. For example, a tweet with a higher than average number of *Happy* words would receive a 1 for the *Happy* item. The dichotomized scores are run through the Rasch model to produce trait scores for the tweets and item locations for the emotion categories.

Under the Rasch model, items receive estimates of their relative frequency of occurrence on the latent dimension, also known as item difficulty or location. An item with a high value on the latent dimension is traditionally described as a difficult item, indicating that it is rarer for this item to be passed. An item with a low value on the latent dimension is traditionally described as an easy item, indicating that it more common for this item to be passed. Like items, persons also recieve a latent score on the same dimension. A high person score indicates that the person is likely to pass more items.

An underlying assumption of the Rasch model is unidimensionality, which is the requirement that there is only one underlying latent trait driving all responses. In standard applications of the Rasch model, this is a trait such as math ability. Here, we propose that the dimension that the texts are scored on is *emotional voice* of the author. If an author writes in a particular style with particular opinions, we propose that the use of emotion categories in their writing will not be random. Rather, particular authors will tend to express certain emotions more regularly than others. There will be a pattern to the expression of emotions that is consistent across writings that goes further than which emotions are common and which are uncommon.

Under the Rasch model, item estimates have meaningful order conditional on the latent dimension. This meaning can be expressed with two priciples. First, an item with a lower estimate is more likely to be passed than an item with a higher estimate. Second, if a person passes a more difficult item, then it is also likely that they also passed the easier items. The item estimates are thus also estimates of conditional probability. Deviation from these assumptions will produce poor model, item, or person fit. This conditional fit underlies the interpretation of the latent dimension as the emotional voice of the author. 

<!-- That is, if an emotion label receives a high estimate, this implies that the emotion label is both rare and generally appears alongside the lower difficulty items. If more rarely endorsed items do no co-occur with more commonly endorsed items, item and model fit will be poor.  -->

In summary for the Emoxicon application of the Rasch model, persons represent tweets and items represent the emotion categories from the DepecheMood++ lexicon. Item categories that have high trait estimations are less likely to appear in a given tweet. Tweets that recieve high trait estimates are more likely to contain many emotion words in many emotion categories. Poor model fit indicates that the emotion catgories are either unrelated to each other and there is no conditional order of the emotion catgories.

Data Pre-processing
-------------------

The purpose of this analysis is to examine differences in tweets written by the IRA among the left-wing and the right-wing troll accounts. We will refer to such tweets as *authored* content. By removing non-authored tweets, we ensure that all the tweets support the goals of the accounts and do not belong to accounts with other "voices." To this end, we included only English-language troll accounts labeled as Left-wing (\"Left\") or Right-wing (\"Right\") by @linvill2019original. URLs, retweets, manual reposts (i.e., tweets that begin with \"rt\"), and duplicate tweets were removed. 

Because the DepecheMood++ lexicon was sourced from news articles, it contains emotion associations for a number of politically relevant words, such as \"Hillary,\" \"Clinton,\" and \"Trump\". We removed a small set of topically relevant terms that we anticipated had different affective associations between the left-wing and right-wing accounts (see the Appendix for a full list of removed words). That is, left-wing and right-wing trolls may use the word \"Trump\" just as frequently, but that word does not have the same relationship to the tweets true emotional content for each group. As these words were used often, they also would artificially inflate their respective category frequency. Similarly, we did not split up multiword hashtags (e.g., "#blacklivesmatter") to prevent misleading category inflation; the emotional valence of the whole hashtag was likely not a sum of its parts. 

Analysis Plan
-------------

We ran two separate but complimentary applications of the *Emoxicon* method to the Russian Trolls dataset: an omnibus Rasch model for the `r sum(table(unique(trolls[c("author", "account_type")])$account_type))` number of Twitter accounts, and `r length(catright)` Rasch models for each individual account. The omnibus Rasch model included all cleaned tweets from both left-wing and right-wing trolls. In this strategy, we are able to identify differences between left-wing and right-wing trolls in the majority of the authored tweets. However, these broad group-level differences obscure the actions of less productive accounts and are largely dominated by a handful of mega-accounts with thousands of self-authored tweets. To compliment the omnibus model, we also ran individual Rasch models for Twitter accounts. This strategy allows us to examine differences between accounts regardless of their productivity. For the individual models, only accounts with at least 30 tweets were included to sufficiently fit each Rasch model [@linacre1994samplesize]. 

Each method used the same data scored with the DepecheMood++ lexicon [@araque2018depechemood]. Using the eight emotion catgories, raw scores ranged from 0 to 8. All models and fit statistics were produced using the R package eRm [@eRm2020]. Exact estimation of full zero/complete response patterns are not available with the eRm conditional maximum likelihood estimator. This is an acceptable trade off in exchange for unbiased person and item estimates [@mair2007cml] and because person estimates are not of direct interest in the Emoxicon method.

The main variable of interest was the estimated item parameters produced by the Rasch model, specifically the item difficulties. In the omnibus model, we used Andersen's likelihood ratio test in the eRm package to identify differences in item difficulties between left-wing and right-wing trolls [@andersen1973goodness; @eRm2020]. 

Because the mean of either the person or item parameters of the Rasch model must be set to zero before estimation to establish the scale and the individual models use separate data, item parameters are not directly comparable across individual Rasch models. Therefore to compare the relative difficulties between models, item parameters from the individual models were transformed into ranks from 1 (easiest) to 8 (hardest) within each model. Ties in rank were broken randomly. The distribution of the ranks could then be examined for consistency within and differences between Right and Left trolls. If an individual account did not use any words from a specific emotion category, that emotion category was given the rank of 8 (hardest to endorse). 

To evaluate the ranks of the emotion categories in the individual models, we examined their distribution using Kolmogorov-Smirnov distribution and Wilcoxon rank-sum tests [@corder2014nonparametric]. In addition, we evaluated the consistency of the item difficulties within the left-wing and right-wing troll groups using the multiinformation (total correlation) function from the R package infotheo [@meyer2008infotheo], and the diversity of the emotion labels using the Gini coefficient [@ong2018emodiversity].

Our final sample consisted of `r nrow(trolls)` tweets from `r table(unique(trolls[c("author", "account_type")])$account_type)[["Right"]]` right-wing accounts ($n_{tweets}$ = `r sum(trolls$account_type == "Right")`) and `r table(unique(trolls[c("author", "account_type")])$account_type)[["Left"]]` left-wing accounts ($n_{tweets}$ = `r sum(trolls$account_type == "Left")`). Among Twitter handles with at least 30 tweets, there were `r sum(catright)` right-wing accounts ($n_{tweets}$ = `r tweets30right`) and `r sum(catleft)` left-wing accounts ($n_{tweets}$ = `r tweets30left`). Tweets dated from `r stringi::stri_split_regex(min(trolls$publish_date), " ")[[1]][1]` to `r stringi::stri_split_regex(max(trolls$publish_date), " ")[[1]][1]`. See Table\ \@ref(tab:tweetTab) for more information on the distribution of the final sample of tweets.


```{r tweetTab}

# rows - left wing and right wing
tweetTab<- data.frame(
  "x" = c("Left-wing, all accounts","Left-wing, 30+ tweets", "Right-wing, all accounts","Right-wing, 30+ tweets"),
  "Accounts, n" = c(table(unique(trolls[c("author", "account_type")])$account_type)[["Left"]],
                    sum(catleft),
                    table(unique(trolls[c("author", "account_type")])$account_type)[["Right"]],
                    sum(catright)),
  "Total Tweets" = c(sum(trolls$account_type == "Left"),
                tweets30left,
                sum(trolls$account_type == "Right"),
                tweets30right),
  "Minimum" = c(min(table(trolls[which(trolls$account_type=="Left"),"author"])),
                30,
                min(table(trolls[which(trolls$account_type=="Right"),"author"])),
                30),
  
  "2nd Quartile" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[2],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[2],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[2],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[2]),
  
  "Median" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[3],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[3],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[3],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[3]),
  
  "3rd Quartile" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[4],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[4],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[4],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[4]),
  
  "Maximum" = c(max(table(trolls[which(trolls$account_type=="Left"),"author"])),
                max(table(trolls[which(trolls$account_type=="Left"),"author"])),
                max(table(trolls[which(trolls$account_type=="Right"),"author"])),
                 max(table(trolls[which(trolls$account_type=="Right"),"author"])))
)
colnames(tweetTab) <- c("x", "Accounts, n", "Total Tweets", "Minimum", "2nd Quartile", "Median", 
                        "3rd Quartile", "Maximum")

apa_table(
  tweetTab
  , caption = "Distribution of Tweets in Accounts"
  , note = "Tweets removed during pre-processing are not included."
  , escape = TRUE
)


```

Results
=======

Omnibus Rasch Model
-------------------
<!-- BY HAND -->
### Model Fit
Overall model fit for the full Rasch model was appropriate. Only `r pmis$PersonMisfit`% of tweets showed significant misfit using a Chi-square based Z-value cutoff of 1.96. The items *Amused* and *Inspired* showed misfit based on chi-squared item fit statistics (
$\chi$(`r ifit$i.df["AMUSED"]`) = `r ifit$i.fit["AMUSED"]`, p = .001 and 
$\chi$(`r ifit$i.df["INSPIRED"]`) = `r ifit$i.fit["INSPIRED"]`, p < .001
, respectively). Due to the large sample size, and the results in the following sections, the misfit in these items is not of great concern.
To check for multidimensionality, we performed a principal components analysis on the Rasch model residuals. The largest eigenvalue was `r round(rasch_pca$pca$eigen.values[1],2)`, indicating that there was not a meaningful impact of multidimensionality on the model fit [@linacre1998rfa].

```{r}
scores<-data.frame(scores = rowSums(trolls_models$full_model$X), 
                   account_type = trolls$account_type)
tweetsscores<-t.test(scores~account_type, scores)

```

Right-wing tweets had slightly higher raw scores (M = `r mean(subset(scores, account_type == "Right")[["scores"]])`, SD = `r sd(subset(scores, account_type == "Right")[["scores"]])`) than Left-wing tweets M = `r mean(subset(scores, account_type == "Left")[["scores"]])`, SD = `r sd(subset(scores, account_type == "Left")[["scores"]])`;
 *t*(`r tweetsscores$parameter`) = `r tweetsscores$statistic`, *p* < .001
), though the difference was empirically small. 
Under the model, estimated item difficulties were generally well-matched to estimated tweet scores (Figure\ \@ref(fig:PImap)). 
In the Rasch model, *Don't Care* was the easiest item with the lowest trait estimates, while *Happy* was the item with the highest trait estimate. The locations of the other items were estimated to be relatively close to one another, indicating that the categories were used at relatively similar rates when both Left-wing and Right-wing trolls were combined.

(ref:fig-PImap) There were `r (1-sum(table(pparameters$thetapar))/nrow(trolls))*100`%  tweets with full zero/complete response patterns. They are not included in the pictured person distribution.

```{r PImap, fig.cap = "(ref:fig-PImap)"}
plotPImap(trolls_models$full_model, sorted = TRUE,
         cex = .5)
```

### Left-wing and Right-wing Differences
<!-- BY HAND -->
The Andersen's likelihood ratio test showed significant differences between the Left-wing and Right-wing troll tweets ($\chi$(7) = `r lrres$LR`, p < .001; Figure\ \@ref(fig:llres)) [@eRm2020]. The items *Amused*, *Afraid*, and *Annoyed* were more difficult among Left-wing Tweets. *Inspired* was more difficult for Right-wing tweets. *Don't Care* and *Angry* were also more difficult for Right-wing tweets, but to a much smaller degree.The items *Happy* and *Sad* were similarly used between both Left-wing and Right-wing trolls. 


(ref:fig-llres) Items closer to the black identity line were estimated more similarly between Left-wing and Right-wing tweets. The 95% confidence intervals are shown in blue for the identity line and in red for the item difficulties.

```{r llres, fig.cap = "(ref:fig-llres)"}
plotGOF(lrres, tlab = "item",
        conf = list(ia = FALSE, col = "red", lty = "dotted"),
        smooline = list(gamma = .95, col = "blue", lty = "solid"),
        main = "Likelihood Ratio Differences between Troll Groups", 
        xlab = "Item Difficulties for Left-wing Tweets",
        ylab = "Item Difficulties for Right-wing Tweets",
        cex = .7, cex.main = .2, cex.axis = .2, cex.lab =.2
          )

```


Individual Rasch Models
-----------------------

### Model Fit
We fit `r length(trolls_models$group_models)` Rasch models for each of the individual Twitter handles with at least 30 authored tweets. Among these models, there were `r table(err_models)[["HAPPY"]]` models with full zero responses for the category *Happy* and `r table(err_models)[["AFRAID"]]` model with full zero responses for the category *Afraid*. The average percentage of misfitting persons was 
`r mean(manymods_pmis_total[modsL])`% (SD = `r sd(manymods_pmis_total[modsL])`) for Left-wing accounts and 
`r mean(manymods_pmis_total[!modsL])`% (SD = `r sd(manymods_pmis_total[!modsL])`) for Right-wing accounts. Item misfit was also generally low (Table\ \@ref(tab:ifittab)). The majority of items misfit in less than 6% of models, except for *Amused*, *Happy*, and *Inspired*. Overall, the measures of model fit were appropriate.


```{r ifittab}
ifittab<-manymod_ifit_tab
apa_table(ifittab,
          caption = "Percent of Models with Misfitting Items"
  # , note = "This table was created with apa_table()."
  , escape = TRUE)

```


### Category Ordering
<!-- BY HAND -->
To compare the estimates between individual models, item parameters were transformed into ranks from 1 (easiest) to 8 (hardest) within each model. 
Figure\ \@ref(fig:catplots) displays the distributions of the order of item difficulties for both left-wing and right-wing troll accounts. Mean rank differences were evaluated by using the Wilcoxon rank sum test. Distributional differences were evaluated with Kolmogorov-Smirnov Tests [@corder2014nonparametric]. Differences in spread were evaluated using Levene's test with the median as the center [@levene1960robust].
Across both groups, the hardest category was *Happy* for `r table(trolls_models$category_order$HAPPY)[["8"]]/length(trolls_models$group_models)*100`% of accounts. 
There were significant median and distributional differences between left-wing and right-wing trolls for the categories 
*Angry* 
(*U*(*n~R~*=`r sum(catright)`, *n~L~*=`r sum(catleft)`) = `r utests$ANGRY$statistic`, *p* < .001; D = `r kstests$ANGRY$statistic`, *p* = < .001), 
*Annoyed* 
(*U*(*n~R~*=`r sum(catright)`, *n~L~*=`r sum(catleft)`) =`r utests$ANNOYED$statistic`, *p* < .001; D = `r kstests$ANNOYED$statistic`, *p* < .001), 
*Sad* 
(*U*(*n~R~*=`r sum(catright)`, *n~L~*=`r sum(catleft)`) = `r utests$SAD$statistic`, *p* < .001; D = `r kstests$SAD$statistic`, *p* < .001), 
and *Afraid* 
(*U*(*n~R~*=`r sum(catright)`, *n~L~*=`r sum(catleft)`) = `r utests$AFRAID$statistic`, *p* < .001; D = `r kstests$AFRAID$statistic`, *p* < .001; 
see Table\ \@ref(tab:msdcat) for means and standard deviations). The category *Don't Care* showed distributional differences (D = `r kstests$DONT_CARE$statistic`, *p* = 0.049), but not median differences. 
The category *Happy* showed a difference in medians (*U*(*n~R~*=`r sum(catright)`, *n~L~*=`r sum(catleft)`) = `r utests$HAPPY$statistic`, *p* = .031) though the empirical mean difference was small.
There were no median or distributional differences in the item difficulty orders for the categories *Amused* or *Inspired*. 
Among Right-wing troll accounts, the categories *Annoyed* and *Afriad* were generally easier. 
Among Left-wing troll accounts, the categories *Angry* and *Sad* were generally easier. 

Differences in variance were found for the categories 
*Angry* (*F*(`r lvtestsd$ANGRY$Df[2]`) = `r lvtestsd$ANGRY[2][1,1]`, *p* < .001)
, *Annoyed* (*F*(`r lvtestsd$ANNOYED$Df[2]`) = `r lvtestsd$ANNOYED[2][1,1]`, *p* = .003)
, and *Inspired* (*F*(`r lvtestsd$INSPIRED$Df[2]`) = `r lvtestsd$INSPIRED[2][1,1]`, *p* < .001)
, while *Amused* (*F*(`r lvtestsd$AMUSED$Df[2]`) = `r lvtestsd$AMUSED[2][1,1]`, *p* = .054)
approached statistical significance. The variance was always larger for the Right-wing trolls among these four categories, indicating higher spread and less interal cohesion around the median.


```{r msdcat}

msdcat <- data.frame("Category" = c("Amused","Angry","Annoyed",
                                    "Don't Care","Inspired",
                                    "Sad", "Afraid", "Happy"),
                     
                     "Mean (SD) - Right-Wing" = paste0(
                       format(round(colMeans(
                         trolls_models$category_order[catright,]),2), nsmall=2),
                       " (",
                       format(round(apply(
                         trolls_models$category_order[catright,],2,sd),2), nsmall=2),
                       ")"),
                     
                     "Mean (SD) - Left-Wing" = paste0(
                       format(round(colMeans(
                         trolls_models$category_order[catleft,]),2), nsmall=2),
                       " (",
                       format(round(apply(
                         trolls_models$category_order[catleft,],2,sd),2), nsmall=2),
                       ")"), stringsAsFactors = F
)
colnames(msdcat) <- c("Category", "Mean (SD) - Right-Wing",  "Mean (SD) - Left-Wing")


apa_table(
  msdcat
  , caption = "Means and Standard Deviations of Emotion Category Orders"
  # , note = "This table was created with apa_table()."
  , escape = TRUE
)
```


(ref:fig-catplots) The distributions of emotion categories within accounts when ordered from 1 (easiest) to 8 (hardest). \u002A indicates significant differences between left-wing and right-wing accounts based on Wilcoxon rank-sum tests. \u2020 indicates significant differences based on Kolmogorov-Smirnov distribution tests.


```{r catplots, fig.cap = "(ref:fig-catplots)", fig.height=5.5}

grid.arrange(catplotsR + theme(text = element_text(size=rel(8)),
                               strip.text.x = element_text(size = 5.5),
                               axis.title.x = element_blank()), 
             
             catplotsL + theme(text = element_text(size=rel(8)),
                               strip.text.x = element_text(size = 5.5)),
             ncol=1)

```


### Gini Index (Emodiversity)
Following @ong2018emodiversity's emodiversity method, we used the Gini coefficient to estimate the diversity in category usage between left-wing and right-wing trolls. High Gini coefficient values indicate more less diversity (more inequality or unevenness) among emotion categories. 
We used the raw emotion scores rather than the Rasch model dichotomized scores.
Left-wing trolls showed more inequality among emotion categories than right-wing trolls when the Gini coefficient was calculated either across all tweets 
(left-wing = `r ginitweetresults$estimate["mean in group Left"]`, right-wing = `r ginitweetresults$estimate["mean in group Right"]`; 
(*t*(`r ginitweetresults$parameter`) = `r ginitweetresults$statistic`, *p* < .001) 
or within authors
(left-wing = `r giniauthorresults$estimate["mean in group Left"]`, right-wing = `r giniauthorresults$estimate["mean in group Right"]`; 
(*t*(`r giniauthorresults$parameter`) = `r giniauthorresults$statistic`, *p* < .001). 


### Multiinformation

We calculated multiinformation (also known as total correlation  [@meyer2008infotheo]) with bootstrapped confidence intervals for the category orders for the left-wing and right-wing accounts to understand the consistency in the orders within groups. 
Higher values of multiinformation signify higher entropy, that is, lower relationships between variables. 
For left-wing accounts, multiinformation was 
`r boot.left$t0` (95% CI [`r bci.left$normal[2]`, `r bci.left$normal[3]`], bias =  `r mean(boot.left[["t"]]) - boot.left$t0`); 
for right-wing accounts, multiinformation was `r boot.right$t0` (95% CI [`r bci.right$normal[2]`, `r bci.right$normal[3]`], bias =  `r mean(boot.right[["t"]]) - boot.right$t0`). 
We also bootstrapped the average multiinformation among a random ordering of the numbers 1 through 8, resulting in a maximum value of multiinformation value of `r boot.random$t0` (95% CI [`r bci.random$normal[2]`,`r bci.random$normal[3]`]) for a data structure like the category orders in this study. Both left-wing and right-wing trolls showed more cohesion in their category orders than would be expected by chance, but they did not differ from one another.

Discussion
==========

Topics to hit:

* How did Emoxicon perform? Did this study support our claims that it is a good method?
* Which emotions were most common? 
* Do these results link up to the previous research on virality and emotions?
* The differences in emotion expression may be linked to different methods of eliciting emotion. Different purposes, topics eliciting different emotions?

*Happy* was the hardest emotion category for both left-wing or right-wing trolls when examining the total number of tweets and the individual models. 

Of note, the emotion categories with that showed misfit most often (*Amused*, *Happy*, and *Inspired*) were also the categories that generally did not show differences between Left-wing and Right-wing trolls.

The higher inequality among Left-wing troll tweets measured via the Gini ceofficient corresponded to the category order results. The variance of the distrubtions of emotion category orders tended to be larger for the Right-wing trolls as compared to the Left-wing trolls. These larger variances imply more variety (evenness) in the difficulties of the emotion categories among the Right-wing accounts. The results of both the Gini coefficient and the category orders suggest that Right-wing troll accounts varied more in their emotional expression than the Left-wing accounts. 



<!-- Interpretation -->
<!-- -------------- -->





<!-- Future Directions -->
<!-- ----------------- -->

Limitations
-----------

It is critical to interpret the results of this study in context of its methods. Emotion is not a universal, context-free phenomenon; statements that are neutral in one context may elicit powerful reactions in another. The emotion categories delineated in the DepecheMood++ lexicon were sourced from a specific time and group membership. When a tweet is rated highly on *Happy*, it does not imply that all readers of the tweet would have the same reaction. This may be even more true when dealing with highly politically and emotionally charged content that was written to elicit strong emotion reactions.

We propose that differences in emotion expression in this study should rightly be interpreted as differences in how one, perhaps neutral, subset of readers may react. We do not believe that these differences are not true or present in reality - rather that it is an overstep to assume that every person who reads a left-wing troll tweet is more likely to react with anger than if they read a right-wing troll tweet.


<!-- Conclusions -->
<!-- ----------- -->


Words removed from Lexicon
==========================

`r paste(exclude, " ")`
