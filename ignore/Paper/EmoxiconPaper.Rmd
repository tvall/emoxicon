---
title             : "Russian Trolls & Emoxicon"
shorttitle        : "Emoxicon"

author: 
  - name          : "Tara L. Valladares"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    email         : "tls8vx@virginia.edu"
    address       : "Postal address"
  - name          : "Hudson Golino"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Virginia"

authornote: |
  This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. 1842490. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.

abstract: |
  This will be the abstract.
  
bibliography      : trolls.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_word
---


```{r setup, include=FALSE}
library(bookdown)
library(gridExtra)
library(papaja)
library(ggplot2)
library(emoxicon)
library(citr)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, warn = FALSE)

# source("EmoxiconPaperAnalysis.Rmd")
load("EmoxiconPaperAnalysis-May-21-2020-dat.RData")
```

Introduction
============

Human communication relies heavily upon digital messages sent through
email, text messaging, and social media platforms. Developing methods
that can analyze unstructured text is therefore critical in numerous
fields, including psychology, political science, and economics.
Specifically, the need for methods of text analysis grows as the broad
spectrum influence of social media platforms such as Facebook and
Twitter increases. As social media platforms are frequent sites of both
information and disinformation campaigns, efforts to identify and
understand these processes are limited by the available tools. In this
paper, we will introduce a new method of emotion extraction and describe
an application to a dataset.

State Sponsored Disinformation and Russian Trolls
-------------------------------------------------

State sponsored disinformation campaigns are not a new phenomenon.
Purposeful efforts to spread false information and \"fake news\" have
been documented since ancient Egypt and Rome. With the rise of the
internet and social media, such campaigns can be conducted at a level
and size that was previously impossible. The Russian state commonly
employs disinformation campaigns in an effort to influence foreign
politics. These campaigns utilize a variety of strategies to sow
discord, including online media manipulation, cyber-espionage, and
falsely inciting protests in the real world
[@richey2018russia; @linvill2019ira].

The term *trolls* or *sock puppet* accounts is commonly used to
described social media accounts that claim to be some person from a
certain background or position, while actually being under direct
control of a hidden third party. This is similar but in contrast to
*bots* which perform similar actions to trolls but are directed by a
computer program rather than a real person. Both trolls and bots have
been extensively used by Russia, and other governments, to manipulate
social media and political discourse around the world.

During the 2016 U.S. presidential election, Russian troll farms posed as
U.S. natives on Twitter in an attempt to influence political discourse
and opinion. This eventually lead to the United States Justice
Department inditing 13 Russian individuals and three Russian entities on
charges relating to interference in the presidential election
[@wapoRussian2018]. The Internet Research Agency (IRA), a company based
in St. Petersburg, was among the companies charged and has been a
primary focus of investigations into state-sponsored Russian
interference in U.S. politics [@schiff2018trolls]. After the Justice
Department released the Twitter handles associated with the IRA, Clemson
university researchers Darren Linvill and Patrick Warren downloaded all
tweets associated with these accounts and made the dataset publicly
available for researchers [@linvill2019original]. The full dataset
consists of nearly 3 million tweets from 2,800 accounts.

The content of the Russian troll tweets ranges widely.
@linvill2019original documented four major categories of
English-language accounts that were active before the 2016 election:
right trolls, left trolls, news feeds, and hashtag gamers. The majority
of tweets from all accounts were deemed innocuous camouflage tweets;
that is, the tweets were not political, but were instead contained
mundane interactions with followers or references to popular culture
[@linvill2019ira]. Political tweets from right-wing accounts largely
supported Donald Trump as the presidential nominee and attacked Hilary
Clinton. Political tweets from left-wing accounts largely attacked
Trump, while less frequently either attacked or supported Clinton. There
were apparent differences in how the account categories tweeted, though.
For example, the right-trolls had less camouflage tweets than the
left-trolls. It was estimated that over half of tweets from left-troll
accounts were camouflage tweets, compared to less than 15% of tweets
from right-troll accounts [@linvill2019ira]. This suggests that left and
right troll accounts were employing different strategies in their
attempts at political influence.


reference Hudson's EGA paper [@golino2020ega]

Because both typical human communication and disinformation campaigns
commonly occur on mediums characterized by brief segments of texts
(e.g., tweets), there is a great need for flexible, low-computation
methods of emotion detection that reliably work on relatively short
documents.

Brief history of emotion extraction
-----------------------------------

An enormous amount of work has been dedicated to extracting sentiment
and emotion from text. As is common in many developing fields, the
nomenclature of techniques can be unclear. Sentiment analysis is often
used as a catchall term to describe the measurement of any feeling in
text, no matter how complex. Here, we will separate the extraction of
emotion from that of sentiment. Sentiment analysis is the process by
which sentiment, i.e., positive and negative opinions, is extracted from
text. Emotion detection focuses on the extraction of emotional
categories, such as happiness, anger, or pride. The distinction between
the sentiment and emotion can lie on a continuum, depending how features
are extracted and utilized. Competing theories and methods may
conceptualize emotions as distinct categories or as lying on related
continuums. When categorical, the emotion categories generally include
anger, disgust, fear, joy, sadness, and surprise, and sometimes trust
and anticipation
[@mohammad2016sentiment; @ekman1992emotions; @hirat2015survey; @strapparava2008learning].
When continuous, popular theories describe emotions as lying on three
dimensional vectors constructed from arousal, valence, and dominance
[@russell2003affect].

### Emotion Lexicons

Lexicons form the basis of most methods of emotion detection. Lexicons
are dictionaries that contain features (such as words or punctuation),
the category they belong to, and their designated score. Lexicons vary
in their size, complexity, and focus. They may be manually created
through annotation or created automatically through machine learning.

Lexicon-based analyses are limited by the lexicon's size and complexity.
In general, the larger the lexicon, the more robust the scoring. Smaller
lexicons may be poor matches to a target text if there is little overlap
in words. Significant bias can occur when a target text is poorly
matched to the lexicon. For this reason, domain-specific lexicons can
give better results than general lexicons, though the creation of
lexicons for every domain and genre is a monumental task. The majority
of lexicons are created or seeded through hand annotation
[@mohammad2016sentiment]. While human generated lexicons have validity
advantages, they will be naturally limited in size and by responder
biases.

### Bag-of-words

Bag-of-words (BOW) is a method of cleaning and organizing text that is
commonly used alongside lexicons. In BOW, all grammar and word placement
is discarded to create an orderless "bag" of word counts. BOW is thus a
method of extracting the word frequency. Lexicon-scored and frequency
data can be analyzed through simple sum scores or with more complex
methods. While BOW and lexicons can serve in standalone analyses,
machine learning frequently makes use of BOW and lexicons to create
features.

Though relatively crude, bag-of-words can produce compelling results on
its own or in combination with machine learning techniques.
[@dasilva2014tweet] found that BOW combined with standard machine
learning algorithms produced accuracy rates of tweet sentiment
classification around 70-80%. There, the addition of sentiment lexicons
always improved classification rates.

Aims
----

The purpose of the current study is to introduce a novel method of
emotion detection, termed Emoxicon, and detail its application to a
dataset of tweets sent by Russian Trolls. *Emoxicon* combines lexicon scoring with Rasch modeling to understand the distribution and probability of emotion categories.

INSERT PARAGRAPH HERE ABOUT WHY THAT IS IMPORTANT - USE OF OF EMOTION AND MANIPULATION


Methods
=======

Emoxicon
--------

Emoxicon is a method of analyzing the emotional content of text. The
Emoxicon method primarily consists of two parts: emotion scoring and
Rasch modeling.

### Lexicon Scoring

Lexicon-based analyses are limited by the lexicon's size and complexity.
In general, the larger the lexicon, the more robust the scoring. Smaller
lexicons may be poor matches to a target text if there is little overlap
in words and significant bias can occur when a target text is poorly
matched to the lexicon. We used the DepecheMood++ lexicon created by
[@araque2018depechemood]. DepecheMood++ is an emotion lexicon that
contains roughly 37 thousand terms and their associated probability
weights for 8 emotion categories. The lexicon was created by scraping
data from the news website Rappler which features a native \"*Mood
Meter*\" widget on each article. Readers of the site are encourage to
select one of eight reactions (Afraid, Amused, Angry, Annoyed, Don't
Care, Happy, Inspired, or Sad) to the article. DepecheMood++ has several
features that make it particularly useful. First, DepecheMood++ was
naively crowdsourced; it did not rely on hand-annotation by
knowledgeable participants. Second, DepecheMood++ is much larger than
other commonly used lexicons. Previous work has shown that the
Depechemood++ lexicon performs as well or better than other emotion
lexicons [@araque2018depechemood; @staiano2014depechemood]

A simple bag-of-words method is applied to score the emotional content
of a given document. In the original lexicon, each word is assigned a
weight for each of the eight dimensions. Here, the lexicon is condensed;
each word in the lexicon becomes associated with the emotion category
with the highest probability weight. Then, each tweet is assigned a sum
score of how many words are most highly associated with each emotion
category.

### The Rasch Model

The Rasch model is used to evaluate the relative probability of the an
emotion weight appearing in a given tweet. By using the Rasch model, we
are able to analyze the fit of the emotion weights to the document. The
Rasch model originated in the field of psychometrics to relate scales
and questionnaires to the underlying latent trait [@Rasch1960]. The
Rasch model is a logistic model that places persons and items on the
same scale to calculate the probability of a given person endorsing a
given item. Fundamentally, the Rasch model can be used to generate
latent trait scores for entities that produces a set of responses
determined by an underlying latent trait. The basic form of the Rasch
model for dichotomous items, as adapted from [@Rasch1960], is:

$$\textit{P}(\textit{X}_{ij} = 1 | \theta_i, \beta_j) = \dfrac{exp(\theta_i - \beta_j)}{ 1 + exp(\theta_i - \beta_j)}$$

Where $\theta$ represents the trait level of person $i$ and $beta$
represents the difficulty or location of item $j$. In Emoxicon, tweets
take the place of persons and emotional scores are represented as items.
Each tweet is scored based on how many words are present from each
emotion category. A mean split was performed on the emotion word counts
within each emotion category to dummy code each tweet as 1 (high) or 0
(low) for each category. For example, a tweet with a relatively high
amount of \"Happy\" words would receive a 1 for the \"Happy\" item. The
dichotomized scores are run through the Rasch model to produce trait
scores for the tweets and 'item' locations for the emotion categories.

An underlying assumption of the Rasch model is unidimensionality, which is the requirement that there is only one underlying latent trait driving all responses. In standard applications of the Rasch model, this is a trait such as math ability. Here, we propose that the dimension that the text is scored on is *emotional voice* of the author. 

Under the Rasch model, items receive estimates of their relative difficulty on the latent dimension. These difficulties have meaningful order. An item with a lower difficulty is more likely to be endorsed than an item with a higher difficulty. If a high difficulty item is endorsed, it is also likely that the lower diffculty items will *also* be endorsed. Deviation from these assumptions will produce poor model fit. Thus, when the Rasch model is used to score emotion data, the item difficulties are also estimates of conditional probability. That is, if an emotion label recieves a high difficulty, this implies that the emotion label is both rare and generally appears alongside the lower difficulty items. This conditional fit underlies the intepretation of the latent dimension as the emotional voice of the author. 


Data Pre-processing
-------------------

The purpose of this analysis is to examine differences in tweets written by the IRA among the left-wing and the right-wing troll accounts. We will refer to such tweets as *authored* content. By removing non-authored tweets, we ensure that all the tweets support the goals of the accounts and do not belong to accounts with other "voices." To this end, we included only English-language troll accounts labeled as Left-wing (\"Left\") or Right-wing (\"Right\") by @linvill2019original. URLs, Retweets, manual reposts (i.e., tweets that begin with \"rt\"), and duplicate tweets were removed. 

Because the Depechmood++ lexicon was sourced from news articles, it contains emotion associations for a number of politically relevant words, such as \"Hillary,\" \"Clinton,\" and \"Trump\". We removed a small set of topically relevant terms that we anitcipated had different connotations between the left-wing and right-wing accounts (see the appendix for a full list of removed words). That is, left-wing and right-wing trolls may use the word \"Trump\" just as frequently, but that word does not have the same relationship to the tweets true emotional content for each group. As these words were used often, they also would artificially inflate their respective category \"easiness\". 

Analysis Plan
-------------

We ran two separate but complimentary applications of the *Emoxicon* method to the Russian Trolls dataset. First, we ran one overarching Rasch model including all cleaned tweets from both left-wing and right-wing trolls. In this strategy, we are able to identify differences between left-wing and right-wing trolls in the majority of the authored tweets. However, these broad group-level differences obscur the actions of less productive accounts and are largely dominated by a handful of mega-accounts with thousands of self-authored tweets. To compliment the overall model, we also ran individual Rasch models for Twitter accounts. This stratgey allows us to examine differences between accounts regardless of their productivity. For the individual models, only accounts with at least 30 tweets were included to sufficiently fit each Rasch model [@linacre1994samplesize]. Each method used the same data scored with the Depechemood++ lexicon [@araque2018depechemood]. All models and fit statistics were produced using the R package eRm [@eRm2020].

The main variable of interest was the estimated item parameters produced by the Rasch model, specfically the item difficulties. In the overarching model, we used Andersen's likelihood ratio test in the eRm pacakge to identify differences in item difficulties between left-wing and right-wing trolls. 

Because the mean of either the person or item parameters of the Rasch model must be set to zero before estimation, item parameters are not directly comparable across individual Rasch models. Therefore to compare the relative difficulties between models, item parameters from the individual models were transformed into ranks from 1 (easiest) to 8 (hardest) within each model. Ties in rank were broken randomly. The distribution of the ranks could then be examined for consistency within and differences between Right and Left trolls. If an individual account did not use any words from a specific emotion category, that emotion category was given the rank of 8 (hardest to endorse). 

To evalute the ranks of the emotion categories in the individual models, we examined their distribution using Kolmogorov-Smirnov distribution and Welch t-tests. In addition, we evaluated the consistency of the item difficulties within the left-wing and right-wing troll groups using mutual information, and the diversity of the emotion labels using the gini coefficient [@ong2018emodiversity].

Our final sample consisted of `r nrow(trolls)` tweets from `r table(unique(trolls[c("author", "account_type")])$account_type)[["Right"]]` right-wing accounts ($n_{tweets}$ = `r sum(trolls$account_type == "Right")`) and `r table(unique(trolls[c("author", "account_type")])$account_type)[["Left"]]` left-wing accounts ($n_{tweets}$ = `r sum(trolls$account_type == "Left")`). Among twitter handles with at least 30 tweets, there were `r sum(catright)` right-wing accounts ($n_{tweets}$ = `r tweets30right`) and `r sum(catleft)` left-wing accounts ($n_{tweets}$ = `r tweets30left`). Tweets dated from `r stringi::stri_split_regex(min(trolls$publish_date), " ")[[1]][1]` to `r stringi::stri_split_regex(max(trolls$publish_date), " ")[[1]][1]`. See table\ \@ref(tab:tweetTab) for more information on tweet distribution of the final sample.


```{r tweetTab}

# rows - left wing and right wing
tweetTab<- data.frame(
  "x" = c("Left-wing, all accounts","Left-wing, 30+ tweets", "Right-wing, all accounts","Right-wing, 30+ tweets"),
  "Accounts, n" = c(table(unique(trolls[c("author", "account_type")])$account_type)[["Left"]],
                    sum(catleft),
                    table(unique(trolls[c("author", "account_type")])$account_type)[["Right"]],
                    sum(catright)),
  "Total Tweets" = c(sum(trolls$account_type == "Left"),
                tweets30left,
                sum(trolls$account_type == "Right"),
                tweets30right),
  "Minimum" = c(min(table(trolls[which(trolls$account_type=="Left"),"author"])),
                30,
                min(table(trolls[which(trolls$account_type=="Right"),"author"])),
                30),
  
  "2nd Quartile" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[2],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[2],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[2],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[2]),
  
  "Median" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[3],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[3],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[3],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[3]),
  
  "3rd Quartile" = c(quantile(table(trolls[which(trolls$account_type=="Left"),"author"]))[4],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Left"), 
                                        "author"]),"author"]))[4],
                     quantile(table(trolls[which(trolls$account_type=="Right"),"author"]))[4],
                     quantile(table(trolls[which(trolls$author %in%
                           author.small[which(author.small$account_type == "Right"), 
                                        "author"]),"author"]))[4]),
  
  "Maximum" = c(max(table(trolls[which(trolls$account_type=="Left"),"author"])),
                max(table(trolls[which(trolls$account_type=="Left"),"author"])),
                max(table(trolls[which(trolls$account_type=="Right"),"author"])),
                 max(table(trolls[which(trolls$account_type=="Right"),"author"])))
)
colnames(tweetTab) <- c("x", "Accounts, n", "Total Tweets", "Minimum", "2nd Quartile", "Median", 
                        "3rd Quartile", "Maximum")

apa_table(
  tweetTab
  , caption = "Distribution of Tweets in Accounts"
  , note = "Tweets removed during pre-processing are not included."
  , escape = TRUE
)


```

Results
=======

Overarching Rasch Model
-------------------

### Model Fit
Overall model fit for the full Rasch model was appropriate. XXX% of tweets showed significant misfit based on M_{2} misfit statistics; person misfit was low. The items XXXXXXX misfit. To check for multidimensionality, we performed a principle components analysis on the Rasch model residuals. The largest eigenvalue was `r round(rasch_pca$pca$eigen.values[1],2)`, indicating that there was not a signficiant impact of mulitdimensionality on the model fit [@linacre1998rfa].

model fit 



Items were generally well-matched to tweet scores (see Figure XXXX for the person-item map). In the full Rasch model, XXXX was the easiest item with the lowest difficulty, while *Happy* was the item with the highest difficulty. The difficulties of items XXX XXX XXX were estimated to be relatively close to one another, indicating that the probabilities of many words from these categoreis appearing in a given tweet was relatively similar.



### Left-wing and Right-wing Differences

The Andersen's likelihood ratio test showed significant differences between the Left-wing and Right-wing trolls. Follow-up analyses indicated that these differences were largest for categories XXXXX (see Figure XXXX).


Individual Rasch Models
-----------------------

### Model Fit
We fit `r length(trolls_models$group_models)` Rasch models for each of the individual twitter handles with at least 30 authored tweets. Among these models, there were `r table(err_models)[["HAPPY"]]` models with full zero responses for the category \"Happy\" and `r table(err_models)[["AFRAID"]]` model with full zero responses for the category *Afraid*. 

The average percentage of misfitting persons was XXX% (sd) for left-wing accounts and XXX% (sd) for right-wing accounts. Item misfit was also generally low (Table XXX). Of note, [where did categories misfit or not]. Overall, the measures of model fit were appropriate.


model fit 


### Category Ordering

Figure\ \@ref(fig:catplots) displays the distributions of the order of item difficulties for both left-wing and right-wing troll accounts. Across both groups, the hardest category was *Happy* for `r table(trolls_models$category_order$HAPPY)[["8"]]/length(trolls_models$group_models)*100`% of accounts. 
There were significant mean and distributional differences between left-wing and right-wing trolls for the categories 
*Angry* (*t*(`r ttests$ANGRY$parameter`) = `r ttests$ANGRY$statistic`, *p* < .001; D = `r kstests$ANGRY$statistic`, *p* = < .001), 
*Annoyed* (*t*(`r ttests$ANNOYED$parameter`) = `r ttests$ANNOYED$statistic`, *p* < .001; D = `r kstests$ANNOYED$statistic`, *p* < .001), 
*Sad* (*t*(`r ttests$SAD$parameter`) = `r ttests$SAD$statistic`, *p* < .001; D = `r kstests$SAD$statistic`, *p* < .001), 
and *Afraid* (*t*(`r ttests$AFRAID$parameter`) = `r ttests$AFRAID$statistic`, *p* < .001; D = `r kstests$AFRAID$statistic`, *p* < .001; see Table\ \@ref(tab:msdcat) for means and standard deviations). The category *Don't Care* showed distributional differences (; D = `r kstests$DONT_CARE$statistic`, *p* = 0.049), but not mean differences. There were no differences in the item difficulty orders for the categorys *Amused*, *Inspired*, or *Happy*.


```{r msdcat}

msdcat <- data.frame("Category" = c("Amused","Angry","Annoyed","Don't Care","Inspired",
                                    "Sad", "Afraid", "Happy"),
                     "Mean (SD) - Right-Wing" = paste0(
                                format(round(colMeans(
                                  trolls_models$category_order[catright,]),2), nsmall=2),
                                         " (",
                                format(round(apply(
                                  trolls_models$category_order[catright,],2,sd),2), nsmall=2),
                                        ")"),
                      "Mean (SD) - Left-Wing" = paste0(
                                format(round(colMeans(
                                  trolls_models$category_order[catleft,]),2), nsmall=2),
                                         " (",
                                format(round(apply(
                                  trolls_models$category_order[catleft,],2,sd),2), nsmall=2),
                                        ")"), stringsAsFactors = F
                     )
colnames(msdcat) <- c("Category", "Mean (SD) - Right-Wing",  "Mean (SD) - Left-Wing")


apa_table(
  msdcat
  , caption = "Means and Standard Deviations of Emotion Category Orders"
  # , note = "This table was created with apa_table()."
  , escape = TRUE
)
```


(ref:fig-catplots) The distributions of emotion categories within accounts when ordered from 1 (easiest) to 8 (hardest). \u002A indicates significant differences between left-wing and right-wing accounts based on *t* tests. \u2020 indicates significant differences based on Kolmogorov-Smirnov distribution tests.


```{r catplots, fig.cap = "(ref:fig-catplots)", fig.height=5.5}

grid.arrange(catplotsR + theme(text = element_text(size=rel(8)),
                               strip.text.x = element_text(size = 5.5),
                               axis.title.x = element_blank()), 
             
             catplotsL + theme(text = element_text(size=rel(8)),
                               strip.text.x = element_text(size = 5.5)),
             ncol=1)

```


### Gini Index (Emodiveristy)

### Mutual Information

As a baseline, we used bootstrapping to calculate the average amount of mutual information for 

### Prediction

Discussion
==========


*Happy* was the hardest emotion category for both left-wing or right-wing trolls when examining the total number of tweets and the individual models.

Interpretation
--------------

The differences in emotion expression may be linked to different methods of eliciting emotion. Different purposes, topics eliciting different emotions

It is critical to interpret the results of this study in context of its methods. Emotion is not a universal, context-free phenomenon; statements that are neutral in one context may elicit powerful reactions in another. The emotion categories delinated in the Depechemood++ lexicon were sourced from a specific time and group membership. When a tweet is rated highly on *Happy*, it does not imply that all readers of the tweet would have the same reaction, above and beyond whatever "error" is present in our scoring system. This may be even more true when dealing with highly politically and emotionally charged content that was written to elicit strong emotion reactions.

We propose that differences in emotion expression in this study should rightly be interpreted as differences in how one, perhaps neutral, subset of readers may react. We do not believe that these differences are not true or present in reality - rather that it is an overstep to assume that every person who reads a left-wing troll tweet is more likely to react with anger than if they read a right-wing troll tweet.




Future Directions
-----------------

Limitations
-----------

Conclusions
-----------


Words removed from Lexicon
==========================

`r paste(exclude)`
